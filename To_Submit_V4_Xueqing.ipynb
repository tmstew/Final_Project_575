{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group member: Ying Yang#\n",
    "\n",
    "What was your biggest challenge in this project?<br>\n",
    "When I tried to read the file 'annotations/var_drug_ann.tsv' by 'pd.read_csv', it takes me much time to fix the ParseError (Error tokenizing data. C error: Expected 12 fields in line 7290, saw 16). After googling and obtaining suggestions from Cristina, I decided to skip the line 7290 using 'error_bad_lines = False'.\n",
    "\n",
    "What did you learn while working on this project?<br>\n",
    "First, I learned to skip the unusable data when it is too hard to fix it. Details please refer to my answers to question 1 (What was your biggest challenge in this project?).\n",
    "Second, I learned that we should try to avoid hardcode which may leads to notable brittleness. Third, I learned to use pandas.DataFrame.fillna() function to fill NA/NaN values instead of exploiting my original complicated 'for loop', reminding me the importance of efficiently exploring different functions provided by packages to reduce the redundancy of my code.\n",
    "\n",
    "If you had more time on the project what other question(s) would you like to answer?<br>\n",
    "First, I would like to investigate which variants have significant associations with drug dosage. The study can be conducted by filtering the merged file by 'SIGNIFICANCE' is 'yes' and 'PHEONOTYPE CATEGORY' is 'dosage'.\n",
    "Second, I am also interested in comparing which variants possess different ALLELE_PharmGKB and ALLELE_23andme in the merged file. These are just two examples of what can be further studied from the perspective of scientific researchers. Actually, the data provided by the two tables in the project is abundant and informative enough for researchers to develop multiple projects to dig thorouly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group member: Xueqing Wang\n",
    "\n",
    "What was your biggest challenge in this project?<br>\n",
    "I had a hard time finding the most appropriate functions to use. It happened several times during the homework that after writing a complicated series of codes to get the desired result, I suddenly realized that there is a pandas function already written to do these things.\n",
    "\n",
    "What did you learn while working on this project?<br>\n",
    "1) always look for ready-to-use functions before starting coding from scratch; 2) care about the usability of the code: always think from the user's perspective, make the input easy and instructions clear, allow space for the user to customize the output; 3) also care about the robustness of the code: add error handling methods at the place where 1) takes a user input; 2) the code may broke down because of changes in the file that the user feeds in.\n",
    "\n",
    "If you had more time on the project what other question(s) would you like to answer?<br>\n",
    "1) write the whole thing into a class; 2) add more error handling points; 3) What're the drugs that target each dbSNP_ID? 4) What's the most effective drug combination for each patient? That is, use the least kinds of drugs to target the most kinds of dbSNPs. 5) For the same gene, targeting at which or which combination of dbSNPs is the most effective and economic? (maybe current information is not enough)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group member: Thomas Stewart\n",
    "\n",
    "What was your biggest challenge in this project? \n",
    "1. The most difficult challenge on this project was the error handling for the 16 vs 12 lines seen by the read_csv function. We ended up talking with Christina about it and learning that we didn't have to worry about it. However I tried several different methods to correct this error and I'm including one of the methods attemped below to demonstrate that we did try to fix this issue:\n",
    "```python\n",
    "i = 0\n",
    "with open('var_drug_ann.tsv') as drugs:\n",
    "    try:\n",
    "        for line in drugs: \n",
    "            if i < 8000:\n",
    "                lst_temp = line.split('\\t')\n",
    "                i += 1\n",
    "                print(len(lst_temp))\n",
    "                print(i)\n",
    "                if len(lst_temp) == 16:\n",
    "                    print(lst_temp)\n",
    "    except UnicodeDecodeError:\n",
    "        print(line)\n",
    "        error_lst_temp = line.split('\\t')\n",
    "        for item in error_lst_temp:\n",
    "            print(type(item))\n",
    "            print(item)\n",
    "```\n",
    "\n",
    "2. Additionally, it was difficult to work with a large and diverse data files but this was just a matter of putting in the time to understand them.\n",
    "\n",
    "What did you learn while working on this project?\n",
    "1. I learned how read_table/read_csv work in terms of their extensive optional arguements that can modify their behavior. I attempted to mimic their logic when testing and error handling but ultimatly found that these functions are far quicker than reading in line by line and seperating. It seems as though most of the functions within pandas are well optimized and each have many of their own functions, classes, attributes, and methods, leading to thousands of lines of code on the GitHub repository for these functions. \n",
    "\n",
    "\n",
    "If you had more time on the project what other question(s) would you like to answer? \n",
    "1. The current solution only applies for the specific files given and could be expaned to included additional file types and databased to make the current comparative analysis more holistic. Additionally, I woudl be interesting to move beyond this surface level understand of drugs and genes to look at some chemical attibutes of these drugs to better understand how we might predict these interactions. Given enough information about the drugs and genes, this could be a great problem to solve with machine learning. \n",
    "2. From a coding standpoint, I think that with more time we could introduce more error handling to include things like informing the user when the file they are trying to use is incorrect or something similar. This would help with the robustness of the program if it is applied to other problems/files. Additionally, we could include this functions and call them in a single script rather than a notebook, however, it makes more sense to use a notebook for this submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Member: Yongkai\n",
    "What was your biggest challenge in this project?<br>\n",
    "The biggest challeng I met is how to read these two files into Python. When I tried to use \"read_table\" or \"read_csv\" for file \"var_drug_ann.tsv\", it gave me an error that there are more elements in one row than others. Somehow I solved this issue by using seperation \"\\t\".\n",
    "\n",
    "What did you learn while working on this project?<br>\n",
    "I learned to use some functions that I didn't familiar with before. Especially, I learned from my teammate Ying Yang about how to use \"groupby\" and \"apply\". I used to stick to \"for\" loop and it could make my code long and messy. And our teammates really make me think about how to write cleaner codes.\n",
    "\n",
    "If you had more time on the project what other question(s) would you like to answer?<br>\n",
    "I wish to answer is there a general way to filter the merged 23andme file and the variant-drug annotation file. My idea is to create a function so that users could choose conditions (like SIGNIFICANCE == yes ) to filter the merged file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "This is the solution for **Project2 - Drug Annotation of 23andme Result**.<br>\n",
    "We wrote two functions and used pandas package for the sake of efficiently compute the required output.<br>\n",
    "The solution is divided into two parts - **main body** and **extra credit**.<br>\n",
    "The main body consists of the first three cells, aiming at output file '23andme_PharmGKB_map.tsv' to achieve the basic requirements of the project.\n",
    "The extra credit part is composed of the last two cells, aiming at creating the required file named 'extra_credit_test.tsv' to gain extra credits.<br>\n",
    "#### **Please simply run our code, and the corresponding files will be created**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_23andme_drug(me23_file = '23andme_v5_hg19_ref.txt.gz', drug_file = 'var_drug_ann.tsv'):\n",
    "    '''This function takes file paths for the 23andMe and var_drug_ann files to merge these files \n",
    "       into a single, cleaned data frame. The default paths for these files are based on the GitHub repo\n",
    "       which can be cloned at:https://github.com/tmstew/Final_Project_575.git.\n",
    "       \n",
    "       Note: This method currently ignores 13 lines of the file that have additional information/are not able to be read in properly. \n",
    "             We are ignoring these lines based on suggestions from Christina.\n",
    "    '''\n",
    "    \n",
    "    # read into files\n",
    "    data23me_names = ['Chromosomes', 'Position', 'Variant', 'Allele']\n",
    "    data23me = pd.read_csv(me23_file, sep = '\\t', names = data23me_names)\n",
    "    data_var_drug = pd.read_csv(drug_file, sep = '\\t', error_bad_lines = False)\n",
    "    # filter\n",
    "    data_var_drug_filtered = data_var_drug.loc[(data_var_drug['Significance'] == 'yes') & (data_var_drug['Phenotype Category'] == 'efficacy')]\n",
    "    # merge dataframes\n",
    "    me23_drug_merged = pd.merge(data23me, data_var_drug_filtered).reset_index(drop = True)\n",
    "    # select columns and set column names for final output\n",
    "    output_df = me23_drug_merged.loc[: ,['Variant', 'Gene', 'Chemical', 'Notes', 'Sentence', 'Alleles', 'Allele']]\n",
    "    output_df.columns = ['dbSNP_ID', 'GENE_SYMBOL', 'DRUG_NAME', 'NOTES', 'SENTENCE', 'ALLELE_PharmGKB', 'ALLELE_23andme']\n",
    "    # replace empty cells with (no entry)\n",
    "    output_df_cleaned = output_df.fillna('(no entry)').replace(to_replace = '', value = '(no entry)')\n",
    "    \n",
    "    return output_df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 7290: expected 12 fields, saw 16\\n'\n"
     ]
    }
   ],
   "source": [
    "# Call the merge_23andme_drug function, please provide path if the files are not in working dir\n",
    "final_df = merge_23andme_drug(me23_file = '23andme_v5_hg19_ref.txt.gz', drug_file = 'var_drug_ann.tsv')\n",
    "final_df.to_csv('23andme_PharmGKB_map.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene_drug_group(merged_df, remove_quotes = False):\n",
    "    '''This function takes in the combined, cleaned data frame from the merge_23andme_drug function.\n",
    "       This function then groups the data by dbSNP_ID and GENE_SYMBOL/DRUG_NAME, outputting these\n",
    "       in a new dataframe.\n",
    "       \n",
    "       Note: 1) If you want to remove the quotation marks around gene and drug names, please set \"remove_quotes\" to \"True\"\n",
    "             2) The split string part of code was inspired by a stackoverflow answer, however the exact page cannot be found now\n",
    "    '''\n",
    "    \n",
    "    # select columns to use\n",
    "    small_df = merged_df.loc[:,['dbSNP_ID','GENE_SYMBOL','DRUG_NAME']]\n",
    "    # split strings in each column\n",
    "    new_df = small_df\n",
    "    for name_string in small_df.columns:\n",
    "        new_series = small_df[name_string].str.split(',', expand = True).stack()\n",
    "        new_series.index = new_series.index.droplevel(-1)\n",
    "        new_series.name = name_string\n",
    "        new_df = new_df.drop(axis = 1, labels = name_string).join(new_series)\n",
    "    # remove quotation marks if required\n",
    "    if remove_quotes == True:\n",
    "        new_df['DRUG_NAME'] = new_df['DRUG_NAME'].str.strip('\"')\n",
    "        new_df['GENE_SYMBOL'] = new_df['GENE_SYMBOL'].str.strip('\"')\n",
    "    # group by GENE_SYMBOL and DRUG_NAME\n",
    "    group = new_df.groupby(['GENE_SYMBOL','DRUG_NAME'])['dbSNP_ID'].apply(';'.join)\n",
    "    df_group = pd.DataFrame(group)\n",
    "    \n",
    "    return df_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the gene_drug_group function, if you want to remove quotation marks please change \"remove_quotes\" to \"True\"\n",
    "df_group = gene_drug_group(final_df, remove_quotes = False)\n",
    "df_group.to_csv('extra_credit_test.tsv', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
